library(tidymodels)
library(embed)
library(vroom)
# library(kknn)
# library(discrim)
# library(naivebayes)

# py_require("tensorflow")
# 
# install.packages("remotes")
# remotes::install_github("rstudio/tensorflow")
# reticulate::install_python()
# keras::install_keras()

trainData <- vroom("train.csv") %>%
  mutate(ACTION = factor(ACTION))
testData <- vroom("test.csv")

my_recipe <- recipe(ACTION ~ ., data=trainData) %>%
  step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
  #step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <.1% i
  step_lencode_mixed(all_factor_predictors(), outcome = vars(ACTION)) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors())
prep <- prep(my_recipe, verbose = TRUE)
baked <- bake(prep, new_data = NULL)

# logRegModel <- logistic_reg() %>% #Type of model
#   set_engine("glm")
# 
# ## Put into a workflow here
# logReg_workflow <- workflow() %>%
#   add_recipe(my_recipe) %>%
#   add_model(logRegModel)

my_mod <- rand_forest(mtry = 1,
                      min_n = 10,
                      trees = 500) %>%
  set_engine("ranger") %>%
  set_mode("classification")

## knn model
# knn_model <- nearest_neighbor(neighbors= tune()) %>% # set or tune
#   set_mode("classification") %>%
# set_engine("kknn")
# 
# knn_wf <- workflow() %>%
# add_recipe(my_recipe) %>%
# add_model(knn_model)

## Fit or Tune Model HERE


## nb model
# nb_model <- naive_Bayes(Laplace=tune(), smoothness=tune()) %>%
# set_mode("classification") %>%
# set_engine("naivebayes") # install discrim library for the naiveb
# 
# nb_wf <- workflow() %>%
# add_recipe(my_recipe) %>%
# add_model(nb_model)

## Tune smoothness and Laplace here

amazon_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
  fit(data = trainData)


# nn_model <- mlp(hidden_units = tune(),
#                 epochs = 50 #or 100 or 250
# ) %>%
# set_engine("keras") %>% #verbose = 0 prints off less
#   set_mode("classification")
# 
# nn_wf <- workflow() %>%
# add_recipe(my_recipe) %>%
# add_model(nn_model)



# # SVM models
# svmPoly <- svm_poly(degree=tune(), cost=tune()) %>% # set or tune
#   set_mode("classification") %>%
# set_engine("kernlab")
# 
# svmRadial <- svm_rbf(rbf_sigma=tune(), cost=tune()) %>% # set or tune
#   set_mode("classification") %>%
# set_engine("kernlab")
# 
# svmLinear <- svm_linear(cost=tune()) %>% # set or tune
#   set_mode("classification") %>%
# set_engine("kernlab")
# 
# svmP_wf <- workflow() %>%
#   add_recipe(my_recipe) %>%
#   add_model(svmPoly)
# svmR_wf <- workflow() %>%
#   add_recipe(my_recipe) %>%
#   add_model(svmRadial)
# svmL_wf <- workflow() %>%
#   add_recipe(my_recipe) %>%
#   add_model(svmLinear)


# tuning_grid <- grid_regular(degree(range = c(1, 3)), cost(range = c(-2, 2)),
#                             levels = 5)

## Grid of values to tune over
#tuning_grid <- grid_regular(mtry(range = c(1, ncol(trainData)-1)), min_n(), levels = 5)
 

## Split data for CV
#folds <- vfold_cv(trainData, v = 5, repeats=1)

## Run the CV
#CV_results <- amazon_workflow %>%
#tune_grid(resamples=folds,
          #grid=tuning_grid,
         # metrics=metric_set(roc_auc)) # f_meas, sens, recall, spec,
                                    # precision, accuracy, Or leave metrics NULL


## Find Best Tuning Parameters1
#bestTune <- CV_results %>%
#select_best()

## Finalize the Workflow & fit it
# final_wf <- amazon_workflow %>%
# finalize_workflow(bestTune) %>%
# fit(data=trainData)


## Predict

## Run all the steps on test data
preds <- predict(amazon_workflow, new_data = testData, type = "prob")


# logReg_fit <- fit(logReg_workflow, data = trainData)
# 
# ## Make predictions
# amazon_predictions <- predict(logReg_fit,
#                               new_data=testData,
#                               type= "prob") # "class" or "prob"
## with type="prob" amazon_predictions will have 2 columns
## one for Pr(0) and the other for Pr(1)!
## with type="class" it will just have one column (0 or 1)

# preds <- preds %>% select(-.pred_0)

final <- preds %>% select(.pred_1)
colnames(final)[1] <- "ACTION"

kaggle_submission <- final %>%
  bind_cols(testData %>% select(id)) %>%
  select(id, ACTION)

vroom_write(x=kaggle_submission, file="./FinalPredictions.csv", delim=",")
